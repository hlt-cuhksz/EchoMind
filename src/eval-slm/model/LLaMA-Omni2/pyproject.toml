[build-system]
requires = ["setuptools>=69.5.1"]
build-backend = "setuptools.build_meta"

[project]
name = "llama_omni2"
version = "1.0.0"
description = "Towards GPT-4o like large language and speech assistant."
readme = "README.md"
requires-python = ">=3.10"
classifiers = [
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: Apache Software License",
]
dependencies = [
    "torch==2.3.1",
    "torchaudio==2.3.1",
    "transformers==4.43.4",
    "tokenizers==0.19.1",
    "sentencepiece==0.1.99",
    "shortuuid==1.0.13",
    "accelerate==0.33.0",
    "peft==0.14.0",
    "bitsandbytes==0.45.0",
    "pydantic==2.7.0",
    "markdown2[all]==2.5.2",
    "numpy==1.26.4",
    "scikit-learn==1.2.2",
    "gradio==5.3.0",
    "gradio_client==1.4.2",
    "requests==2.32.3",
    "httpx==0.28.1",
    "uvicorn==0.30.0",
    "fastapi==0.115.11",
    "einops==0.6.1",
    "einops-exts==0.0.4",
    "timm==0.6.13",
    "openai-whisper==20231117",
    "datasets==2.18.0",
    "conformer==0.3.2",
    "diffusers==0.27.2",
    "lightning==2.2.4",
    "gdown==5.1.0",
    "wget==3.2",
    "inflect==7.3.1",
    "WeTextProcessing==1.0.3",
    "HyperPyYAML==1.2.2",
    "onnxruntime-gpu==1.18.0",
    "omegaconf==2.3.0",
    "huggingface-hub==0.25.1",
    "hydra-core==1.3.2",
    "librosa==0.10.2",
    "onnx==1.16.0",
    "matplotlib==3.10.1"
]

[project.optional-dependencies]
train = [
    "deepspeed==0.14.2",
    "ninja==1.11.1.3",
    "wandb==0.19.1",
    "tensorboardX==2.6.2.2"
]
build = ["build", "twine"]

[tool.setuptools.packages.find]
include = ["llama_omni2"]

[tool.wheel]
universal = false